{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosimo-schiavoni/Massive_Data_Project/blob/main/Comics_Faces_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the connection to a GPU."
      ],
      "metadata": {
        "id": "u7p3Ap8y7BZO"
      },
      "id": "u7p3Ap8y7BZO"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8VThIbCShB9L",
        "outputId": "3fa2d822-d1b9-4ad2-8ec3-0041e19640cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8VThIbCShB9L",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep  1 23:35:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    32W /  70W |   2872MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the Kaggle package."
      ],
      "metadata": {
        "id": "710Q-cFj9kvY"
      },
      "id": "710Q-cFj9kvY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "7C3Z3PXl7LxN"
      },
      "id": "7C3Z3PXl7LxN",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the kaggle.json file in order to execute the download of the dataset. (Each user should upload his own file)."
      ],
      "metadata": {
        "id": "oGZBU4HXOAyj"
      },
      "id": "oGZBU4HXOAyj"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "AuoAPGS5afc7",
        "outputId": "eaccd107-0c27-4109-d9c6-67264dd77d65"
      },
      "id": "AuoAPGS5afc7",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e49fc34e-3fe1-40c8-8667-915e6e675f9d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e49fc34e-3fe1-40c8-8667-915e6e675f9d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries."
      ],
      "metadata": {
        "id": "bDXa4L1w9rPJ"
      },
      "id": "bDXa4L1w9rPJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras import optimizers, regularizers\n",
        "from functools import reduce\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import keras\n",
        "import pickle\n",
        "import shutil\n",
        "import random\n",
        "import skimage.io as io\n",
        "from copy import deepcopy\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "o2jkdHdo7TZx"
      },
      "id": "o2jkdHdo7TZx",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset from a remote repository."
      ],
      "metadata": {
        "id": "STR5925a93kc"
      },
      "id": "STR5925a93kc"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"data_source\"] = \"./Face_Comics_data\"\n",
        "\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "if not os.path.exists(os.environ[\"data_source\"]):\n",
        "  os.makedirs(os.environ[\"data_source\"])\n",
        "  if \"comic-faces-paired-synthetic-v2\" not in os.listdir():\n",
        "    if \"comic-faces-paired-synthetic-v2.zip\" not in os.listdir():\n",
        "      ! kaggle datasets download -d defileroff/comic-faces-paired-synthetic-v2\n",
        "      with zipfile.ZipFile(\"comic-faces-paired-synthetic-v2.zip\", 'r') as f:\n",
        "        f.extractall(\"comic-faces-paired-synthetic-v2\")\n",
        "    os.remove(\"comic-faces-paired-synthetic-v2.zip\")\n",
        "\n",
        "\n",
        "!mv \"./comic-faces-paired-synthetic-v2/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/comics\" \"./Face_Comics_data\"\n",
        "!mv \"./comic-faces-paired-synthetic-v2/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/faces\" \"./Face_Comics_data\"\n",
        "\n",
        "!rm -rf comic-faces-paired-synthetic-v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A8XXBVUU_o_",
        "outputId": "eb73a05e-3989-47c9-b574-8a755b30f66c"
      },
      "id": "4A8XXBVUU_o_",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat './comic-faces-paired-synthetic-v2/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/comics': No such file or directory\n",
            "mv: cannot stat './comic-faces-paired-synthetic-v2/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/faces': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define data augmentation functions to be implemented in the analysis."
      ],
      "metadata": {
        "id": "BqLHyph-98oz"
      },
      "id": "BqLHyph-98oz"
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "\n",
        "@tf.function\n",
        "def random_invert_img(x, p=0.5):\n",
        "  if  tf.random.uniform([]) < p:\n",
        "    x = (180-x)\n",
        "  else:\n",
        "    x\n",
        "  return x\n",
        "\n",
        "###Randim invert\n",
        "@tf.function \n",
        "def random_invert(factor=0.5):\n",
        "  return layers.Lambda(lambda x: random_invert_img(x, factor))\n",
        "\n",
        "#@tf.function \n",
        "class RandomInvert(layers.Layer):\n",
        "  @tf.function \n",
        "  def __init__(self, factor=0.5, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.factor = factor\n",
        "  @tf.function \n",
        "  def call(self, x):\n",
        "    return random_invert_img(x)\n",
        "\n",
        "\n",
        "###Kernel Inizializer Sobel_x\n",
        "@tf.function \n",
        "def hedge_detector(shape, dtype=None):\n",
        "    print(shape)    \n",
        "    sobel_x = tf.constant(\n",
        "        [\n",
        "            [-5, -4, 0, 4, 5], \n",
        "            [-8, -10, 0, 10, 8], \n",
        "            [-10, -20, 0, 20, 10], \n",
        "            [-8, -10, 0, 10, 8], \n",
        "            [-5, -4, 0, 4, 5]\n",
        "        ], dtype=dtype )\n",
        "    #create the missing dims.\n",
        "    sobel_x = tf.reshape(sobel_x, (5, 5, 1, 1))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    #tile the last 2 axis to get the expected dims.\n",
        "    sobel_x = tf.tile(sobel_x, (1, 1, shape[-2],shape[-1]))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    return sobel_x\n",
        "\n",
        "@tf.function \n",
        "def vertical_detector(shape, dtype=None):\n",
        "    print(shape)    \n",
        "    sobel_x = tf.constant(\n",
        "        [\n",
        "            [1, 0, -1], \n",
        "            [1, 0, -1], \n",
        "            [1, 0, -1]\n",
        "        ], dtype=dtype )\n",
        "    #create the missing dims.\n",
        "    sobel_x = tf.reshape(sobel_x, (3, 3, 1, 1))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    #tile the last 2 axis to get the expected dims.\n",
        "    sobel_x = tf.tile(sobel_x, (1, 1, shape[-2],shape[-1]))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    return sobel_x\n",
        "\n",
        "@tf.function \n",
        "def horizontal_detector(shape, dtype=None):\n",
        "    print(shape)    \n",
        "    sobel_x = tf.constant(\n",
        "        [\n",
        "            [1, 1, 1], \n",
        "            [0, 0, 0], \n",
        "            [-1, -1, -1]\n",
        "        ], dtype=dtype )\n",
        "    #create the missing dims.\n",
        "    sobel_x = tf.reshape(sobel_x, (3, 3, 1, 1))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    #tile the last 2 axis to get the expected dims.\n",
        "    sobel_x = tf.tile(sobel_x, (1, 1, shape[-2],shape[-1]))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    return sobel_x"
      ],
      "metadata": {
        "id": "GOCGF4YHS-kc"
      },
      "id": "GOCGF4YHS-kc",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the CNN model, the Training and the Validation dataset. "
      ],
      "metadata": {
        "id": "ap80MVhi-bBD"
      },
      "id": "ap80MVhi-bBD"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_compiled_model_1():\n",
        "  ###Create CNN\n",
        "  ##Initialize the CNN\n",
        "  model_1 = tf.keras.models.Sequential()\n",
        "        \n",
        "  model_1.add(tf.keras.Sequential([\n",
        "      layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.3),\n",
        "    layers.RandomContrast(0.5, seed=None),\n",
        "    RandomInvert(),\n",
        "    layers.RandomZoom(height_factor=(-0.2, +0.3)),\n",
        "    layers.RandomTranslation(height_factor=(-0.2, +0.3),width_factor=(-0.2, +0.3)),\n",
        "    layers.Rescaling(1./255, offset= -1)\n",
        "    ]))\n",
        "\n",
        "  #NORMAL\n",
        "  #Convolution\n",
        "  model_1.add(tf.keras.layers.Conv2D(32, kernel_size=5, strides=2, activation='relu',  input_shape = [350,350,3]))\n",
        "  #Pooling\n",
        "  model_1.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "  #Convolution\n",
        "  model_1.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3,  strides=2, activation = 'relu'))\n",
        "  #Pooling\n",
        "  model_1.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "  #Second Convolutional Layer\n",
        "  model_1.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 2,  strides=2, activation = 'relu'))\n",
        "  model_1.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides=1, padding='same'))\n",
        "  #Flattening\n",
        "  model_1.add(tf.keras.layers.Flatten())\n",
        "  #Full Connection\n",
        "  model_1.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "  #Output Layer\n",
        "  model_1.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))\n",
        "\n",
        "  ###Training CNN\n",
        "  ##Compiling the CNN\n",
        "  model_1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['mse'])\n",
        "  return model_1\n",
        "\n",
        "def get_compiled_model_2():\n",
        "    #Convolution\n",
        "    model_2.add(tf.keras.layers.Conv2D(32, kernel_size=5, strides=2, activation='relu',  input_shape = [350,350,3]))\n",
        "    #Pooling\n",
        "    model_2.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "    #Convolution\n",
        "    model_2.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3,  strides=2, activation = 'relu'))\n",
        "    #Pooling\n",
        "    model_2.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "    #Second Convolutional Layer\n",
        "    model_2.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 2,  strides=2, activation = 'relu'))\n",
        "    model_2.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides=1, padding='same'))\n",
        "    #Flattening\n",
        "    model_2.add(tf.keras.layers.Flatten())\n",
        "        #Full Connection\n",
        "    model_2.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "    #DROPOUTS ok(0.1)\n",
        "    model_2.add(tf.keras.layers.Dropout(0.1))\n",
        "    #Output Layer\n",
        "    model_2.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))\n",
        "    return model_2\n",
        "\n",
        "def get_compiled_model_3():\n",
        "\n",
        "    #Convolution\n",
        "    model_3.add(tf.keras.layers.Conv2D(32, kernel_size=5, kernel_initializer = hedge_detector, strides=2, activation='relu',  input_shape = [350,350,3]))\n",
        "    #Pooling\n",
        "    model_3.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "    #Convolution\n",
        "    model_3.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3,  strides=2, activation = 'relu',kernel_regularizer =tf.keras.regularizers.l1( l=0.01)))\n",
        "    #Pooling\n",
        "    model_3.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "    #Second Convolutional Layer\n",
        "    model_3.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 2,  strides=2, activation = 'relu',kernel_regularizer =tf.keras.regularizers.l1( l=0.01)))\n",
        "    model_3.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides=1, padding='same'))\n",
        "    #Third Convolutional Layer\n",
        "    #cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 2, activation = 'relu'))\n",
        "    #cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides=2))\n",
        "    #Flattening\n",
        "    model_3.add(tf.keras.layers.Flatten())\n",
        "    #Full Connection\n",
        "    model_3.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "    #Output Layer\n",
        "    model_3.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))\n",
        "    return model_3\n",
        "\n",
        "def get_compiled_model_4():\n",
        "    #Convolution\n",
        "    model_4.add(tf.keras.layers.Conv2D(32, kernel_size=5, kernel_initializer = hedge_detector, strides=2, activation='relu',  input_shape = [350,350,3]))\n",
        "    #Pooling\n",
        "    model_4.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "    #Convolution\n",
        "    model_4.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3,  strides=2, activation = 'relu',kernel_regularizer =tf.keras.regularizers.l2( l=0.01)))\n",
        "    #Pooling\n",
        "    model_4.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "    #Second Convolutional Layer\n",
        "    model_4.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 2,  strides=2, activation = 'relu',kernel_regularizer =tf.keras.regularizers.l2( l=0.01)))\n",
        "    model_4.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides=1, padding='same'))\n",
        "    #Third Convolutional Layer\n",
        "    #cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 2, activation = 'relu'))\n",
        "    #cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides=2))\n",
        "    #Flattening\n",
        "    model_4.add(tf.keras.layers.Flatten())\n",
        "    #Full Connection\n",
        "    model_4.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "    #Output Layer\n",
        "    model_4.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))\n",
        "    return model_4\n",
        "\n",
        "def get_dataset():\n",
        "    BUFFER_SIZE = 10000\n",
        "\n",
        "    BATCH_SIZE_PER_REPLICA = 64\n",
        "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "\n",
        "    data_dir= \"./Face_Comics_data\"\n",
        "\n",
        "    tf.random.set_seed(123456)\n",
        "\n",
        "    EPOCHS = 15\n",
        "    IMG_SIZE = (350, 350)\n",
        "\n",
        "    os.listdir(data_dir)\n",
        "\n",
        "\n",
        "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=0.3,\n",
        "        subset=\"training\",\n",
        "        shuffle=True,\n",
        "        seed=123456,\n",
        "        image_size= IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "    validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=0.4,\n",
        "        subset=\"validation\",\n",
        "        shuffle=True,\n",
        "        seed=123456,\n",
        "        image_size= IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE)\n",
        "    \n",
        "    val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "    test_dataset = validation_dataset.take(val_batches // 5)\n",
        "    validation_dataset = validation_dataset.skip(val_batches // 5)\n",
        "    print('Number of training batches: %d' % tf.data.experimental.cardinality(train_dataset))\n",
        "    print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "    print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))\n",
        "\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return (\n",
        "        train_dataset,\n",
        "        validation_dataset,\n",
        "        test_dataset\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "okjz2Jwgcg5Q"
      },
      "id": "okjz2Jwgcg5Q",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative models can be substituted to the Normal one."
      ],
      "metadata": {
        "id": "Dj1KB6gDCHdG"
      },
      "id": "Dj1KB6gDCHdG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Mirrored strategy in order to distribute computation with Tensorflow engine."
      ],
      "metadata": {
        "id": "gT0A8KaX-jbu"
      },
      "id": "gT0A8KaX-jbu"
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n"
      ],
      "metadata": {
        "id": "ZnbOv3Hne5Zj",
        "outputId": "8429334e-d498-45af-967a-6b1643b0dcb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZnbOv3Hne5Zj",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Strategy scope, and put the compiled model inside it."
      ],
      "metadata": {
        "id": "Ps8_c_tW-tZo"
      },
      "id": "Ps8_c_tW-tZo"
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model_1 = get_compiled_model_1()\n",
        "    model_2 = get_compiled_model_2()\n",
        "    model_3 = get_compiled_model_3()\n",
        "    model_4 = get_compiled_model_4()"
      ],
      "metadata": {
        "id": "MlVYkLPfe7Jj"
      },
      "id": "MlVYkLPfe7Jj",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model on all available devices."
      ],
      "metadata": {
        "id": "fRQhoERg-95S"
      },
      "id": "fRQhoERg-95S"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, validation_dataset, test_dataset = get_dataset()\n",
        "model_fit = model.fit(train_dataset, epochs=2, validation_data=validation_dataset)\n",
        "model_fit"
      ],
      "metadata": {
        "id": "yjK1TJ_Ve8ds",
        "outputId": "5cb88071-d6d6-4362-e680-165cccc98533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yjK1TJ_Ve8ds",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Using 14000 files for training.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Using 8000 files for validation.\n",
            "Number of training batches: 219\n",
            "Number of validation batches: 100\n",
            "Number of test batches: 25\n",
            "Epoch 1/2\n",
            "219/219 [==============================] - 127s 494ms/step - loss: 0.6077 - mse: 0.2094 - val_loss: 0.6723 - val_mse: 0.2502\n",
            "Epoch 2/2\n",
            "219/219 [==============================] - 106s 474ms/step - loss: 0.5726 - mse: 0.1940 - val_loss: 0.4582 - val_mse: 0.1502\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08c17b3410>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "vr7XGURuuZJ-",
        "outputId": "a02d4cee-bfe6-44d6-ab7b-fa3b01d08861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vr7XGURuuZJ-",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_3 (Sequential)   (None, 350, 350, 3)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 173, 173, 32)      2432      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 86, 86, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 42, 42, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 21, 21, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 10, 10, 32)        4128      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 10, 10, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               409728    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 425,665\n",
            "Trainable params: 425,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model on all available devices."
      ],
      "metadata": {
        "id": "uXOxf094_Cow"
      },
      "id": "uXOxf094_Cow"
    },
    {
      "cell_type": "code",
      "source": [
        "stringlist = []\n",
        "model.summary(line_length=70, print_fn=lambda x: stringlist.append(x))\n",
        "\n",
        "substring = 'Trainable params'\n",
        "\n",
        "c = 0\n",
        "for n in stringlist:\n",
        "    if substring not in n:\n",
        "      c += 1\n",
        "    else:\n",
        "      break\n",
        "\n",
        "substring = stringlist[c]  \n",
        "Model_parameters_n = int(\"\".join([i for i in substring if i.isdigit()]))\n",
        "Model_parameters_n"
      ],
      "metadata": {
        "id": "soSWmxxrlzHL",
        "outputId": "55cbd2c9-cdf1-410c-c670-a16c1bee15ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "soSWmxxrlzHL",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "425665"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = model_fit.history['mse']"
      ],
      "metadata": {
        "id": "gi1V8gERe5sg"
      },
      "id": "gi1V8gERe5sg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse"
      ],
      "metadata": {
        "id": "vvy0spOsfWFm"
      },
      "id": "vvy0spOsfWFm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(14000 * np.log(0.2268851101398468) ) + (2*Model_parameters_n)\n",
        "(14000 * np.log(0.17049580812454224) ) + (2*Model_parameters_n)\n"
      ],
      "metadata": {
        "id": "NNI0AnQagdxH"
      },
      "id": "NNI0AnQagdxH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "hifoupSce9kk"
      },
      "id": "hifoupSce9kk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Train and Validation loss and accuracy graph."
      ],
      "metadata": {
        "id": "JHVs1mwT_RNV"
      },
      "id": "JHVs1mwT_RNV"
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model_fit.history['accuracy']\n",
        "val_acc = model_fit.history['val_accuracy']\n",
        "loss_ = model_fit.history['loss']\n",
        "val_loss_ = model_fit.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy', color = 'gray',linestyle='dashed')\n",
        "plt.plot(val_acc, label='Validation Accuracy', color = 'black')\n",
        "plt.ylim([0.8, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss_, label='Training Loss', color = 'gray',linestyle='dashed')\n",
        "plt.plot(val_loss_, label='Validation Loss', color = 'black')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JeUtrqxxXElP"
      },
      "id": "JeUtrqxxXElP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Copy of Downloads.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}