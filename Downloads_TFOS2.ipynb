{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosimo-schiavoni/Massive_Data_Project/blob/main/Downloads_TFOS2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8VThIbCShB9L",
        "outputId": "b818acae-fd21-4b4e-e7cd-e434a08f2713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8VThIbCShB9L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www-eu.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
        "!rm spark-3.2.1-bin-hadoop2.7.tgz\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install findspark\n",
        "!pip install pyspark\n",
        "!pip install -q kaggle\n",
        "!pip install tensorflowonspark\n",
        "!pip install sparkdl\n",
        "!pip install tensorframes\n",
        "!pip install petastorm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcEQwefubdsC",
        "outputId": "e873dd7f-56ec-404a-ecad-9c1f80c63000"
      },
      "id": "hcEQwefubdsC",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 38 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 47.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=96803725fd2e5d9cd4c20aa4def62df1e4c09d13b59212c6ab246ae8cf1e1fb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Collecting tensorflowonspark\n",
            "  Downloading tensorflowonspark-2.2.5-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflowonspark) (21.3)\n",
            "Requirement already satisfied: setuptools>38.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowonspark) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflowonspark) (3.0.9)\n",
            "Installing collected packages: tensorflowonspark\n",
            "Successfully installed tensorflowonspark-2.2.5\n",
            "Collecting sparkdl\n",
            "  Downloading sparkdl-0.2.2-py3-none-any.whl (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 5.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: sparkdl\n",
            "Successfully installed sparkdl-0.2.2\n",
            "Collecting tensorframes\n",
            "  Downloading tensorframes-0.2.9-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: tensorframes\n",
            "Successfully installed tensorframes-0.2.9\n",
            "Collecting petastorm\n",
            "  Downloading petastorm-0.11.4-py2.py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting diskcache>=3.0.0\n",
            "  Downloading diskcache-5.4.0-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from petastorm) (6.0.1)\n",
            "Requirement already satisfied: pyspark>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from petastorm) (3.2.1)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=15.0 in /usr/local/lib/python3.7/dist-packages (from petastorm) (21.3)\n",
            "Requirement already satisfied: psutil>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from petastorm) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from petastorm) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from petastorm) (1.3.5)\n",
            "Requirement already satisfied: pyzmq>=14.0.0 in /usr/local/lib/python3.7/dist-packages (from petastorm) (22.3.0)\n",
            "Requirement already satisfied: future>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from petastorm) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from petastorm) (1.15.0)\n",
            "Requirement already satisfied: dill>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from petastorm) (0.3.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=15.0->petastorm) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.0->petastorm) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.0->petastorm) (2.8.2)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark>=2.1.0->petastorm) (0.10.9.3)\n",
            "Installing collected packages: fsspec, diskcache, petastorm\n",
            "Successfully installed diskcache-5.4.0 fsspec-2022.3.0 petastorm-0.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def main():\n",
        "def main_fun(argv, ctx):\n",
        "  import tensorflow as tf\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # tf.app.run()\n",
        "  #Spark\n",
        "  import pyspark\n",
        "  from pyspark.sql import SparkSession\n",
        "  from pyspark import SparkContext, SparkConf\n",
        "  from pyspark.sql import SQLContext\n",
        "  from pyspark.ml.feature import OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler\n",
        "  from pyspark.ml import Pipeline\n",
        "  from pyspark.sql.functions import rand\n",
        "  from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "  # Keras / Deep Learning\n",
        "  import tensorflow as tf\n",
        "  from tensorflowonspark import TFParallel\n",
        "  from tensorflowonspark import TFCluster\n",
        "  import argparse\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers.core import Dense, Dropout, Activation\n",
        "  from keras import optimizers, regularizers\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  #from my model\n",
        "  import matplotlib\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib.image as mpimg\n",
        "  import keras\n",
        "  from tensorflow.keras import layers\n",
        "  from tensorflow.keras.models import Model\n",
        "  import pickle\n",
        "  import shutil\n",
        "  import random\n",
        "  import skimage.io as io\n",
        "  from copy import deepcopy\n",
        "  import tensorflow_datasets as tfds\n",
        "  import os\n",
        "  from functools import reduce\n",
        "  from google.colab import files\n",
        "  import os\n",
        "  import zipfile\n",
        "  import numpy as np\n",
        "  import tensorflow_datasets as tfds\n",
        "\n",
        "  sc = SparkContext(conf=SparkConf().setAppName(\"TFOS\"))\n",
        "  executors = sc._conf.get(\"spark.executor.instances\")\n",
        "  num_executors = int(executors) if executors is not None else 1\n",
        "\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument(\"--cluster_size\", help=\"number of nodes in the cluster (for S with labelspark Standalone)\", type=int, default=num_executors)\n",
        "  parser.add_argument('--images_labels', type=str, help='Directory for input images with labels')\n",
        "  parser.add_argument(\"--export_dir\", help=\"HDFS path to export model\", type=str, default=\"mnist_export\")\n",
        "  parser.add_argument(\"--output\", help=\"HDFS path to save predictions\", type=str, default=\"predictions\")\n",
        "  args, _ = parser.parse_known_args()\n",
        "  print(\"args: {}\".format(args))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvdCPzoGxuI5",
        "outputId": "b95fc4ca-0e83-4239-a16c-0d71337b3262"
      },
      "id": "XvdCPzoGxuI5",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args: Namespace(cluster_size=1, export_dir='mnist_export', images_labels=None, output='predictions')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "import kaggle\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "AuoAPGS5afc7",
        "outputId": "ab874701-aa38-4987-d455-6e77bf6037df"
      },
      "id": "AuoAPGS5afc7",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f8d46f44-54cb-4865-848c-cda187988be9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f8d46f44-54cb-4865-848c-cda187988be9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"data_source\"] = \"./Face_Comics_data\"\n",
        "\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "if not os.path.exists(os.environ[\"data_source\"]):\n",
        "  os.makedirs(os.environ[\"data_source\"])\n",
        "  if \"comic-faces-paired-synthetic-v2\" not in os.listdir():\n",
        "    if \"comic-faces-paired-synthetic-v2.zip\" not in os.listdir():\n",
        "      ! kaggle datasets download -d defileroff/comic-faces-paired-synthetic-v2\n",
        "      with zipfile.ZipFile(\"comic-faces-paired-synthetic-v2.zip\", 'r') as f:\n",
        "        f.extractall(\"comic-faces-paired-synthetic-v2\")\n",
        "    os.remove(\"comic-faces-paired-synthetic-v2.zip\")\n",
        "\n",
        "\n",
        "!mv \"./comic-faces-paired-synthetic-v2/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/comics\" \"./Face_Comics_data\"\n",
        "!mv \"./comic-faces-paired-synthetic-v2/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/faces\" \"./Face_Comics_data\"\n",
        "\n",
        "!rm -rf comic-faces-paired-synthetic-v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A8XXBVUU_o_",
        "outputId": "19c1b9ab-5b48-435e-ffaf-6e2ecf28da90"
      },
      "id": "4A8XXBVUU_o_",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading comic-faces-paired-synthetic-v2.zip to /content\n",
            " 99% 2.16G/2.18G [00:15<00:00, 184MB/s]\n",
            "100% 2.18G/2.18G [00:15<00:00, 150MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "yg0G4GPBMYXr",
        "outputId": "d66202f5-9143-46bb-b903-21e75ff119c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yg0G4GPBMYXr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "id": "27XrabO_MeGP",
        "outputId": "72320b3d-fbfc-4425-d257-0d7e061cd463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "id": "27XrabO_MeGP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4a2e30848668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of devices: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h10RLnUMM5dc"
      },
      "id": "h10RLnUMM5dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir= \"./Face_Comics_data\"\n",
        "\n",
        "tf.random.set_seed(123456)\n",
        "\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (350, 350)\n",
        "\n",
        "os.listdir(data_dir)\n",
        "\n",
        "\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.3,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    seed=123456,\n",
        "    image_size= IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.3,\n",
        "    subset=\"validation\",\n",
        "    shuffle=True,\n",
        "    seed=123456,\n",
        "    image_size= IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "x2eIzIjqpSPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2c6d9a-fcfb-4750-d559-b1f582ab0889"
      },
      "id": "x2eIzIjqpSPs",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Using 14000 files for training.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Using 6000 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_dataset:\n",
        "  train_label = labels_batch\n",
        "  train_features = image_batch"
      ],
      "metadata": {
        "id": "hAnkUet0ViZw"
      },
      "id": "hAnkUet0ViZw",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = tf.strings.split(file_path, '/')[-2]\n",
        "  return tf.io.read_file(file_path), label\n",
        "flowers_root = pathlib.Path(data_dir)\n",
        "for item in flowers_root.glob(\"*\"):\n",
        "  print(item.name)\n",
        "list_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*'))\n",
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())\n",
        "labeled_ds = list_ds.map(process_path)\n",
        "for image_raw, label_text in labeled_ds.take(1): #this line throws\n",
        "  features = image_raw.numpy()\n",
        "  label = label_text.numpy()\n"
      ],
      "metadata": {
        "id": "cA7Y20Q6wLuo",
        "outputId": "cb7d54fb-3fb2-439f-e96b-0684f12d816d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cA7Y20Q6wLuo",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comics\n",
            "faces\n",
            "b'Face_Comics_data/faces/7362.jpg'\n",
            "b'Face_Comics_data/comics/7665.jpg'\n",
            "b'Face_Comics_data/comics/4451.jpg'\n",
            "b'Face_Comics_data/comics/3101.jpg'\n",
            "b'Face_Comics_data/faces/1231.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn():\n",
        "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.3,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    seed=123456,\n",
        "    image_size= IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "qP1Rr_fgy27T"
      },
      "id": "qP1Rr_fgy27T",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for features_batch, labels_batch in input_fn().take(1):\n",
        "  print(features_batch)\n",
        "  print(labels_batch)"
      ],
      "metadata": {
        "id": "1iDLBTDRyUl9",
        "outputId": "f823a527-c487-4a62-a5fe-2b2dfab5eadc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1iDLBTDRyUl9",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:02:57,510 INFO (MainThread-63) Load dataset info from /root/tensorflow_datasets/iris/2.0.0\n",
            "2022-05-18 02:02:57,519 INFO (MainThread-63) Reusing dataset iris (/root/tensorflow_datasets/iris/2.0.0)\n",
            "2022-05-18 02:02:57,521 INFO (MainThread-63) Constructing tf.data.Dataset for split train, from /root/tensorflow_datasets/iris/2.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dense_input': <tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
            "array([[5.1, 3.4, 1.5, 0.2],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [5.7, 2.6, 3.5, 1. ]], dtype=float32)>}\n",
            "tf.Tensor([0 2 1 2 0 1 1 1 0 2 1 0 2 0 0 0 0 0 2 2 2 2 2 0 2 0 2 1 1 1 1 1], shape=(32,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_ds"
      ],
      "metadata": {
        "id": "0TTRBfHgxx1t",
        "outputId": "23705a7a-4452-48f7-c801-c25d9dc6bb92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0TTRBfHgxx1t",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrNdYr_xWHot",
        "outputId": "17b02e20-1d88-4199-c5cd-543859108bd9"
      },
      "id": "UrNdYr_xWHot",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 350, 350, 3), dtype=float32, numpy=\n",
              "array([[[[ 20.095177 ,  18.095177 ,  19.095177 ],\n",
              "         [  9.35626  ,   9.133402 ,   9.244831 ],\n",
              "         [ 13.270939 ,  13.270939 ,  13.270939 ],\n",
              "         ...,\n",
              "         [ 66.88589  ,  66.88589  ,  68.88589  ],\n",
              "         [ 64.85425  ,  62.854248 ,  65.63147  ],\n",
              "         [ 58.78629  ,  54.78629  ,  55.78629  ]],\n",
              "\n",
              "        [[  9.56956  ,   7.56956  ,   8.56956  ],\n",
              "         [ 12.64374  ,  12.420882 ,  12.5323105],\n",
              "         [ 13.426408 ,  13.426408 ,  13.426408 ],\n",
              "         ...,\n",
              "         [ 68.19945  ,  68.19945  ,  70.19945  ],\n",
              "         [ 53.98846  ,  53.56765  ,  55.555275 ],\n",
              "         [ 37.420105 ,  35.420105 ,  36.420105 ]],\n",
              "\n",
              "        [[ 10.381184 ,   8.381184 ,   9.381184 ],\n",
              "         [  6.3977547,   6.174897 ,   6.286326 ],\n",
              "         [ 11.257143 ,  11.257143 ,  11.257143 ],\n",
              "         ...,\n",
              "         [ 31.24394  ,  32.24394  ,  34.24394  ],\n",
              "         [ 22.426874 ,  22.426874 ,  24.204096 ],\n",
              "         [ 26.146261 ,  26.146261 ,  26.146261 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 37.441483 ,  41.441483 ,  44.441483 ],\n",
              "         [ 31.375723 ,  35.375725 ,  38.375725 ],\n",
              "         [ 28.95224  ,  32.95224  ,  35.95224  ],\n",
              "         ...,\n",
              "         [244.61765  , 172.84023  ,  94.60675  ],\n",
              "         [235.32983  , 157.10706  ,  82.536255 ],\n",
              "         [233.98088  , 151.35234  ,  82.09526  ]],\n",
              "\n",
              "        [[ 44.88607  ,  48.10885  ,  52.99746  ],\n",
              "         [ 24.63118  ,  27.853958 ,  32.74257  ],\n",
              "         [ 35.077026 ,  38.299805 ,  43.188416 ],\n",
              "         ...,\n",
              "         [241.33575  , 165.11298  ,  89.54217  ],\n",
              "         [232.43065  , 153.52963  ,  86.82685  ],\n",
              "         [225.59155  , 147.03711  ,  88.482666 ]],\n",
              "\n",
              "        [[ 22.205786 ,  27.205786 ,  31.205786 ],\n",
              "         [ 38.186825 ,  43.186825 ,  47.186825 ],\n",
              "         [ 32.255356 ,  37.255356 ,  41.255356 ],\n",
              "         ...,\n",
              "         [230.91888  , 151.10461  ,  80.84754  ],\n",
              "         [227.89275  , 152.       ,  92.6353   ],\n",
              "         [218.85019  , 146.85156  ,  99.035736 ]]],\n",
              "\n",
              "\n",
              "       [[[155.15271  , 139.15271  , 124.15271  ],\n",
              "         [149.85556  , 133.85556  , 118.85557  ],\n",
              "         [154.97931  , 138.97931  , 123.97931  ],\n",
              "         ...,\n",
              "         [163.15121  , 146.15121  , 130.15121  ],\n",
              "         [165.9835   , 148.9835   , 130.9835   ],\n",
              "         [166.80464  , 149.80464  , 129.80464  ]],\n",
              "\n",
              "        [[154.81015  , 138.81015  , 125.58729  ],\n",
              "         [153.11143  , 137.11143  , 123.88857  ],\n",
              "         [153.5214   , 137.5214   , 124.29853  ],\n",
              "         ...,\n",
              "         [161.65776  , 144.65776  , 128.65776  ],\n",
              "         [163.61885  , 146.61885  , 130.19803  ],\n",
              "         [171.42918  , 154.42918  , 136.42918  ]],\n",
              "\n",
              "        [[158.0069   , 142.0069   , 129.0069   ],\n",
              "         [157.44286  , 141.44286  , 128.44286  ],\n",
              "         [156.30244  , 140.30244  , 127.30245  ],\n",
              "         ...,\n",
              "         [158.01083  , 140.01083  , 126.01084  ],\n",
              "         [162.69063  , 145.69063  , 129.69063  ],\n",
              "         [162.14171  , 145.14171  , 129.14171  ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[151.36456  , 135.36456  , 122.36456  ],\n",
              "         [153.5585   , 137.5585   , 124.5585   ],\n",
              "         [152.48819  , 136.48819  , 123.48819  ],\n",
              "         ...,\n",
              "         [148.77977  , 131.77977  , 123.77978  ],\n",
              "         [149.39215  , 132.39215  , 124.39215  ],\n",
              "         [140.89803  , 123.898026 , 115.898026 ]],\n",
              "\n",
              "        [[146.40173  , 130.40173  , 117.178955 ],\n",
              "         [151.30942  , 135.30942  , 122.08664  ],\n",
              "         [154.15005  , 138.15005  , 124.927284 ],\n",
              "         ...,\n",
              "         [148.26141  , 131.26141  , 123.261406 ],\n",
              "         [150.21037  , 133.21037  , 125.21037  ],\n",
              "         [145.85576  , 128.85576  , 120.85576  ]],\n",
              "\n",
              "        [[151.49089  , 135.49089  , 120.49089  ],\n",
              "         [145.55025  , 129.55025  , 114.55025  ],\n",
              "         [150.18571  , 134.18571  , 119.185715 ],\n",
              "         ...,\n",
              "         [141.46672  , 124.46672  , 116.46672  ],\n",
              "         [140.11972  , 123.11972  , 115.11972  ],\n",
              "         [160.4893   , 143.4893   , 135.4893   ]]],\n",
              "\n",
              "\n",
              "       [[[ 46.161087 ,  44.161087 ,  47.161087 ],\n",
              "         [ 38.0867   ,  36.0867   ,  39.0867   ],\n",
              "         [ 36.601185 ,  34.601185 ,  37.601185 ],\n",
              "         ...,\n",
              "         [  4.4526443,   4.4526443,   4.4526443],\n",
              "         [  5.4868765,   5.4868765,   5.4868765],\n",
              "         [ 16.37755  ,  16.37755  ,  16.37755  ]],\n",
              "\n",
              "        [[ 40.513004 ,  40.290146 ,  42.401577 ],\n",
              "         [ 38.18847  ,  37.96561  ,  40.077038 ],\n",
              "         [ 36.004246 ,  35.781387 ,  37.892815 ],\n",
              "         ...,\n",
              "         [  8.741561 ,   8.741561 ,   8.741561 ],\n",
              "         [ 10.8788595,  10.8788595,  10.8788595],\n",
              "         [  9.726055 ,   9.726055 ,   9.726055 ]],\n",
              "\n",
              "        [[ 42.037144 ,  42.037144 ,  44.037144 ],\n",
              "         [ 35.243553 ,  35.243553 ,  37.243553 ],\n",
              "         [ 32.045307 ,  32.045307 ,  34.045307 ],\n",
              "         ...,\n",
              "         [  9.777429 ,   9.777429 ,   9.777429 ],\n",
              "         [  6.373931 ,   6.373931 ,   6.373931 ],\n",
              "         [  9.452539 ,   9.452539 ,   9.452539 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 56.81031  ,  67.81031  ,  71.81031  ],\n",
              "         [ 58.264297 ,  69.26429  ,  73.26429  ],\n",
              "         [ 59.371445 ,  70.371445 ,  74.371445 ],\n",
              "         ...,\n",
              "         [ 60.       ,  69.       ,  74.       ],\n",
              "         [ 60.59424  ,  67.59424  ,  73.59424  ],\n",
              "         [ 66.18573  ,  71.18573  ,  77.18573  ]],\n",
              "\n",
              "        [[ 58.148533 ,  69.14853  ,  73.14853  ],\n",
              "         [ 60.88853  ,  71.888535 ,  75.888535 ],\n",
              "         [ 56.961327 ,  67.96133  ,  71.96133  ],\n",
              "         ...,\n",
              "         [ 57.519897 ,  66.5199   ,  71.5199   ],\n",
              "         [ 61.334167 ,  68.33417  ,  74.33417  ],\n",
              "         [ 66.60645  ,  71.60645  ,  77.60645  ]],\n",
              "\n",
              "        [[ 61.63237  ,  72.63238  ,  76.63238  ],\n",
              "         [ 54.268036 ,  65.268036 ,  69.268036 ],\n",
              "         [ 55.438587 ,  66.43859  ,  70.43859  ],\n",
              "         ...,\n",
              "         [ 58.668335 ,  67.668335 ,  72.668335 ],\n",
              "         [ 60.259766 ,  67.259766 ,  73.259766 ],\n",
              "         [ 77.74356  ,  82.74356  ,  88.74356  ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 17.056654 ,  15.056653 ,  16.056654 ],\n",
              "         [ 13.918823 ,  11.918823 ,  12.918823 ],\n",
              "         [ 15.345223 ,  13.345223 ,  14.345223 ],\n",
              "         ...,\n",
              "         [  7.1788   ,   5.1788   ,   6.1788   ],\n",
              "         [  9.67259  ,   5.6725907,   6.6725907],\n",
              "         [ 18.526054 ,  12.526055 ,  14.526055 ]],\n",
              "\n",
              "        [[ 10.680988 ,  10.458131 ,  10.56956  ],\n",
              "         [ 13.544726 ,  13.321869 ,  13.433298 ],\n",
              "         [ 13.537837 ,  13.31498  ,  13.426408 ],\n",
              "         ...,\n",
              "         [ 10.850085 ,   8.850085 ,   9.850085 ],\n",
              "         [ 10.977877 ,   8.557064 ,   9.557064 ],\n",
              "         [  9.0560055,   5.056005 ,   6.056005 ]],\n",
              "\n",
              "        [[  8.306898 ,   8.306898 ,   8.306898 ],\n",
              "         [  9.802081 ,   9.802081 ,   9.802081 ],\n",
              "         [  8.894081 ,   8.894081 ,   8.894081 ],\n",
              "         ...,\n",
              "         [  7.92865  ,   7.92865  ,   7.92865  ],\n",
              "         [  6.812676 ,   4.812676 ,   5.812676 ],\n",
              "         [ 12.043667 ,  10.043667 ,  11.043667 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 56.36881  ,  61.36881  ,  65.36881  ],\n",
              "         [ 50.788    ,  55.788    ,  59.788    ],\n",
              "         [ 52.626205 ,  57.626205 ,  61.626205 ],\n",
              "         ...,\n",
              "         [ 45.068993 ,  36.034496 ,  38.965504 ],\n",
              "         [ 45.891357 ,  31.689268 ,  31.46216  ],\n",
              "         [ 58.847355 ,  39.415462 ,  35.63141  ]],\n",
              "\n",
              "        [[ 61.198036 ,  66.19803  ,  70.19803  ],\n",
              "         [ 54.272346 ,  59.272346 ,  63.272346 ],\n",
              "         [ 53.05203  ,  58.05203  ,  62.05203  ],\n",
              "         ...,\n",
              "         [ 53.96295  ,  43.96295  ,  44.59149  ],\n",
              "         [ 59.11139  ,  43.77722  ,  40.88861  ],\n",
              "         [ 72.23925  ,  51.226852 ,  46.230984 ]],\n",
              "\n",
              "        [[ 60.639164 ,  65.63916  ,  69.63916  ],\n",
              "         [ 58.288605 ,  63.288605 ,  67.288605 ],\n",
              "         [ 54.466324 ,  59.466324 ,  63.466324 ],\n",
              "         ...,\n",
              "         [ 53.631226 ,  43.259766 ,  42.445496 ],\n",
              "         [ 57.52798  ,  42.185547 ,  39.30107  ],\n",
              "         [ 86.78067  ,  62.817783 ,  58.743565 ]]],\n",
              "\n",
              "\n",
              "       [[[245.88719  , 246.88719  , 240.88719  ],\n",
              "         [252.9257   , 253.9257   , 247.9257   ],\n",
              "         [249.19261  , 250.19261  , 244.19261  ],\n",
              "         ...,\n",
              "         [248.51709  , 249.51709  , 243.51709  ],\n",
              "         [247.66014  , 248.656    , 242.66014  ],\n",
              "         [242.73473  , 243.73473  , 237.73473  ]],\n",
              "\n",
              "        [[251.06601  , 252.06601  , 246.06601  ],\n",
              "         [246.4333   , 247.4333   , 241.4333   ],\n",
              "         [246.11143  , 247.11143  , 241.11143  ],\n",
              "         ...,\n",
              "         [248.71796  , 249.71796  , 243.71796  ],\n",
              "         [253.23248  , 254.23248  , 248.23248  ],\n",
              "         [251.92567  , 252.92567  , 246.92567  ]],\n",
              "\n",
              "        [[249.18571  , 250.18571  , 244.18571  ],\n",
              "         [247.92572  , 248.92572  , 242.92572  ],\n",
              "         [244.33694  , 245.33694  , 239.33694  ],\n",
              "         ...,\n",
              "         [250.6522   , 251.6522   , 245.6522   ],\n",
              "         [247.57352  , 248.57352  , 242.57352  ],\n",
              "         [247.74696  , 248.74696  , 242.74696  ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[207.57068  , 211.57068  , 188.21301  ],\n",
              "         [213.58719  , 215.81004  , 193.69862  ],\n",
              "         [209.40598  , 211.40598  , 189.40598  ],\n",
              "         ...,\n",
              "         [152.01707  , 166.98257  , 126.45752  ],\n",
              "         [162.02185  , 172.91046  , 141.7975   ],\n",
              "         [174.7917   , 182.7917   , 158.97743  ]],\n",
              "\n",
              "        [[218.2517   , 222.36308  , 195.02892  ],\n",
              "         [215.66576  , 218.       , 193.33154  ],\n",
              "         [214.94475  , 216.94475  , 192.94475  ],\n",
              "         ...,\n",
              "         [158.8857   , 173.8857   , 133.25716  ],\n",
              "         [168.73009  , 179.73009  , 147.73009  ],\n",
              "         [188.18546  , 197.18546  , 169.96268  ]],\n",
              "\n",
              "        [[233.58336  , 238.58336  , 206.58336  ],\n",
              "         [224.01889  , 227.24174  , 198.13033  ],\n",
              "         [205.97504  , 208.97504  , 181.97504  ],\n",
              "         ...,\n",
              "         [167.88599  , 182.88599  , 141.88599  ],\n",
              "         [176.71954  , 188.71954  , 152.65358  ],\n",
              "         [202.7746   , 212.7746   , 178.70175  ]]],\n",
              "\n",
              "\n",
              "       [[[ 13.870939 ,  11.870939 ,  12.870939 ],\n",
              "         [ 10.797836 ,  10.574979 ,  10.686408 ],\n",
              "         [ 15.30404  ,  15.30404  ,  15.30404  ],\n",
              "         ...,\n",
              "         [  4.6452885,   8.645288 ,   7.6452885],\n",
              "         [  7.9545827,  11.954582 ,  10.954582 ],\n",
              "         [ 11.933248 ,  15.933248 ,  14.933248 ]],\n",
              "\n",
              "        [[  7.800695 ,   5.800695 ,   6.800695 ],\n",
              "         [ 12.225716 ,  12.002859 ,  12.114288 ],\n",
              "         [ 16.057837 ,  16.057837 ,  16.057837 ],\n",
              "         ...,\n",
              "         [  9.536494 ,  13.536494 ,  12.536494 ],\n",
              "         [  7.9901695,  11.99017  ,  10.99017  ],\n",
              "         [  6.5032983,  10.503299 ,   9.503299 ]],\n",
              "\n",
              "        [[  8.462367 ,   6.462367 ,   7.462367 ],\n",
              "         [  9.6192255,   9.396367 ,   9.507796 ],\n",
              "         [ 12.079795 ,  12.079795 ,  12.079795 ],\n",
              "         ...,\n",
              "         [ 10.079903 ,  14.079903 ,  13.079903 ],\n",
              "         [  7.412605 ,  11.412604 ,  10.412604 ],\n",
              "         [  9.023158 ,  13.023158 ,  12.023158 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 54.04404  ,  65.04404  ,  71.04404  ],\n",
              "         [ 51.979305 ,  62.979305 ,  68.9793   ],\n",
              "         [ 51.74292  ,  62.74292  ,  68.74292  ],\n",
              "         ...,\n",
              "         [ 70.37146  ,  70.       ,  70.18573  ],\n",
              "         [ 74.32056  ,  71.48285  ,  72.062065 ],\n",
              "         [ 82.89843  ,  72.46654  ,  71.68249  ]],\n",
              "\n",
              "        [[ 59.14857  ,  69.148575 ,  78.148575 ],\n",
              "         [ 54.433105 ,  64.433105 ,  73.433105 ],\n",
              "         [ 51.524193 ,  61.524193 ,  70.52419  ],\n",
              "         ...,\n",
              "         [ 77.07684  ,  70.742676 ,  72.63129  ],\n",
              "         [ 82.0025   ,  71.53213  ,  72.53213  ],\n",
              "         [ 94.96527  ,  78.453766 ,  78.565155 ]],\n",
              "\n",
              "        [[ 59.007732 ,  69.00774  ,  79.00774  ],\n",
              "         [ 51.789345 ,  61.789345 ,  71.789345 ],\n",
              "         [ 50.81691  ,  60.81691  ,  70.81691  ],\n",
              "         ...,\n",
              "         [ 82.563896 ,  70.563896 ,  72.563896 ],\n",
              "         [ 88.80838  ,  72.2639   ,  75.11954  ],\n",
              "         [111.78067  ,  86.7793   ,  89.597885 ]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in validation_dataset:\n",
        "  validation_label = labels_batch\n",
        "  validation_features = image_batch"
      ],
      "metadata": {
        "id": "kNGOcdw3oGYy"
      },
      "id": "kNGOcdw3oGYy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_label = np.concatenate([y for x, y in train_dataset], axis=0)\n",
        "\n",
        "test_label = np.concatenate([y for x, y in validation_dataset], axis=0) \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2R3vk9INOXMI"
      },
      "id": "2R3vk9INOXMI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.shape(train_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkNp-_rzRnkG",
        "outputId": "8ddc4ef8-13eb-461e-f46e-b90940532470"
      },
      "id": "CkNp-_rzRnkG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "\n",
        "@tf.function\n",
        "def random_invert_img(x, p=0.5):\n",
        "  if  tf.random.uniform([]) < p:\n",
        "    x = (180-x)\n",
        "  else:\n",
        "    x\n",
        "  return x\n",
        "\n",
        "###Randim invert\n",
        "@tf.function \n",
        "def random_invert(factor=0.5):\n",
        "  return layers.Lambda(lambda x: random_invert_img(x, factor))\n",
        "\n",
        "@tf.function \n",
        "class RandomInvert(layers.Layer):\n",
        "  @tf.function \n",
        "  def __init__(self, factor=0.5, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.factor = factor\n",
        "  @tf.function \n",
        "  def call(self, x):\n",
        "    return random_invert_img(x)\n",
        "\n",
        "\n",
        "###Kernel Inizializer Sobel_x\n",
        "@tf.function \n",
        "def hedge_detector(shape, dtype=None):\n",
        "    print(shape)    \n",
        "    sobel_x = tf.constant(\n",
        "        [\n",
        "            [-5, -4, 0, 4, 5], \n",
        "            [-8, -10, 0, 10, 8], \n",
        "            [-10, -20, 0, 20, 10], \n",
        "            [-8, -10, 0, 10, 8], \n",
        "            [-5, -4, 0, 4, 5]\n",
        "        ], dtype=dtype )\n",
        "    #create the missing dims.\n",
        "    sobel_x = tf.reshape(sobel_x, (5, 5, 1, 1))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    #tile the last 2 axis to get the expected dims.\n",
        "    sobel_x = tf.tile(sobel_x, (1, 1, shape[-2],shape[-1]))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    return sobel_x\n",
        "\n",
        "@tf.function \n",
        "def vertical_detector(shape, dtype=None):\n",
        "    print(shape)    \n",
        "    sobel_x = tf.constant(\n",
        "        [\n",
        "            [1, 0, -1], \n",
        "            [1, 0, -1], \n",
        "            [1, 0, -1]\n",
        "        ], dtype=dtype )\n",
        "    #create the missing dims.\n",
        "    sobel_x = tf.reshape(sobel_x, (3, 3, 1, 1))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    #tile the last 2 axis to get the expected dims.\n",
        "    sobel_x = tf.tile(sobel_x, (1, 1, shape[-2],shape[-1]))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    return sobel_x\n",
        "\n",
        "@tf.function \n",
        "def horizontal_detector(shape, dtype=None):\n",
        "    print(shape)    \n",
        "    sobel_x = tf.constant(\n",
        "        [\n",
        "            [1, 1, 1], \n",
        "            [0, 0, 0], \n",
        "            [-1, -1, -1]\n",
        "        ], dtype=dtype )\n",
        "    #create the missing dims.\n",
        "    sobel_x = tf.reshape(sobel_x, (3, 3, 1, 1))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    #tile the last 2 axis to get the expected dims.\n",
        "    sobel_x = tf.tile(sobel_x, (1, 1, shape[-2],shape[-1]))\n",
        "\n",
        "    print(tf.shape(sobel_x))\n",
        "    return sobel_x"
      ],
      "metadata": {
        "id": "GOCGF4YHS-kc"
      },
      "id": "GOCGF4YHS-kc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Create CNN\n",
        "#Initialize the CNN\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\"\"\"    \n",
        "cnn.add(tf.keras.Sequential([\n",
        "\tlayers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "\tlayers.RandomRotation(0.3),\n",
        "    layers.RandomContrast(0.5, seed=None),\n",
        "    RandomInvert(),\n",
        "    layers.RandomZoom(height_factor=(-0.2, +0.3)),\n",
        "    layers.RandomTranslation(height_factor=(-0.2, +0.3),width_factor=(-0.2, +0.3)),\n",
        "    layers.Rescaling(1./255, offset= -1)\n",
        "    ]))\n",
        "\"\"\"\n",
        "#DROPOUT\n",
        "#Introduce the Convolution layer with Kernel_initializer=Sobel_x\n",
        "#Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(32, kernel_size=5, strides=2, activation='relu',  input_shape = [350,350,3]))\n",
        "#Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "#Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3,  strides=2, activation = 'relu'))\n",
        "#Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
        "#Second Convolutional Layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 2,  strides=2, activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides=1, padding='same'))\n",
        "#Third Convolutional Layer\n",
        "#cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 2, activation = 'relu'))\n",
        "#cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides=2))\n",
        "#Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "#Full Connection\n",
        "cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "#DROPOUTS ok(0.1)\n",
        "cnn.add(tf.keras.layers.Dropout(0.1))\n",
        "#Output Layer\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))\n",
        "###Training CNN\n",
        "#Compiling the CNN\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#training the CNN on the train_dataset and validate it on the validation_dataset\n",
        "#model_fit = cnn.fit(x = train_dataset, validation_data = validation_dataset, epochs = EPOCHS)\n",
        "\n",
        "cnn.summary()\n"
      ],
      "metadata": {
        "id": "wVzJSDk8WxxD",
        "outputId": "02088a31-eb4e-4747-b8f9-56894639b0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wVzJSDk8WxxD",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 173, 173, 32)      2432      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 86, 86, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 42, 42, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 21, 21, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 10, 10, 32)        4128      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 10, 10, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               409728    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 425,665\n",
            "Trainable params: 425,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "model_dir = tempfile.mkdtemp()\n",
        "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
        "    keras_model=cnn, model_dir=model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdM-UhOGH457",
        "outputId": "13464e1a-9b8c-416a-9ad2-923935645ec1"
      },
      "id": "PdM-UhOGH457",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:03:38,657 INFO (MainThread-63) Using default config.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using the Keras model provided.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:03:38,661 INFO (MainThread-63) Using the Keras model provided.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp0gfdqbwz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:03:39,306 INFO (MainThread-63) Using config: {'_model_dir': '/tmp/tmp0gfdqbwz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn():\n",
        "  split = tfds.Split.TRAIN\n",
        "  dataset = tfds.load('iris', split=split, as_supervised=True)\n",
        "  dataset = dataset.map(lambda features, labels: ({'dense_input':features}, labels))\n",
        "  dataset = dataset.batch(32).repeat()\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "0zA2zyAprqSD"
      },
      "id": "0zA2zyAprqSD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_estimator.train(input_fn=input_fn, steps=500)\n",
        "eval_result = keras_estimator.evaluate(input_fn=input_fn, steps=10)\n",
        "print('Eval result: {}'.format(eval_result))"
      ],
      "metadata": {
        "id": "51kf-LW8rXOp",
        "outputId": "8edeb501-9cd6-4f2f-89b5-323927732efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "51kf-LW8rXOp",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Using 14000 files for training.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:18,875 INFO (MainThread-63) Calling model_fn.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,430 INFO (MainThread-63) Done calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmp0gfdqbwz/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,438 INFO (MainThread-63) Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmp0gfdqbwz/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Warm-starting from: /tmp/tmp0gfdqbwz/keras/keras_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,444 INFO (MainThread-63) Warm-starting from: /tmp/tmp0gfdqbwz/keras/keras_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,448 INFO (MainThread-63) Warm-starting variables only in TRAINABLE_VARIABLES.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Warm-started 10 variables.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,512 INFO (MainThread-63) Warm-started 10 variables.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,525 INFO (MainThread-63) Create CheckpointSaverHook.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,748 INFO (MainThread-63) Graph was finalized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,872 INFO (MainThread-63) Running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:19,894 INFO (MainThread-63) Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:20,511 INFO (MainThread-63) Calling checkpoint listeners before saving checkpoint 0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp0gfdqbwz/model.ckpt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:20,521 INFO (MainThread-63) Saving checkpoints for 0 into /tmp/tmp0gfdqbwz/model.ckpt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-18 02:11:20,657 INFO (MainThread-63) Calling checkpoint listeners after saving checkpoint 0...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1360\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1361\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,350,350,3]\n\t [[{{node conv2d_3_input}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-598665e50b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eval result: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1184\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1217\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1218\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;31m# trace should be enabled for every step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         tf.compat.v1.logging.warn('Training with estimator made no steps. '\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         logging.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1371\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1394\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1396\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'conv2d_3_input' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 965, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-57-598665e50b69>\", line 1, in <module>\n      keras_estimator.train(input_fn=input_fn, steps=500)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 360, in train\n      loss = self._train_model(input_fn, hooks, saving_listeners)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1186, in _train_model\n      return self._train_model_default(input_fn, hooks, saving_listeners)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1215, in _train_model_default\n      self.config)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1174, in _call_model_fn\n      model_fn_results = self._model_fn(features=features, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/keras_lib.py\", line 328, in model_fn\n      optimizer_config=optimizer_config)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/keras_lib.py\", line 237, in _clone_and_build_model\n      optimizer_config=optimizer_config)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/models.py\", line 680, in clone_and_build_model\n      clone = clone_model(model, input_tensors=input_tensors)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/models.py\", line 454, in clone_model\n      model, input_tensors=input_tensors, layer_fn=clone_function)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/models.py\", line 330, in _clone_sequential_model\n      if isinstance(layer, InputLayer) else layer_fn(layer))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/models.py\", line 56, in _clone_layer\n      return layer.__class__.from_config(layer.get_config())\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py\", line 517, in from_config\n      return cls(**config)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_layer.py\", line 205, in __init__\n      ragged=ragged)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 1386, in placeholder\n      x = tf.compat.v1.placeholder(dtype, shape=shape, name=name)\nNode: 'conv2d_3_input'\nYou must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,350,350,3]\n\t [[{{node conv2d_3_input}}]]\n\nOriginal stack trace for 'conv2d_3_input':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 965, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-57-598665e50b69>\", line 1, in <module>\n    keras_estimator.train(input_fn=input_fn, steps=500)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 360, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1186, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1215, in _train_model_default\n    self.config)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1174, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/keras_lib.py\", line 328, in model_fn\n    optimizer_config=optimizer_config)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/keras_lib.py\", line 237, in _clone_and_build_model\n    optimizer_config=optimizer_config)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/models.py\", line 680, in clone_and_build_model\n    clone = clone_model(model, input_tensors=input_tensors)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/models.py\", line 454, in clone_model\n    model, input_tensors=input_tensors, layer_fn=clone_function)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/models.py\", line 330, in _clone_sequential_model\n    if isinstance(layer, InputLayer) else layer_fn(layer))\n  File \"/usr/local/lib/python3.7/dist-packages/keras/models.py\", line 56, in _clone_layer\n    return layer.__class__.from_config(layer.get_config())\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py\", line 517, in from_config\n    return cls(**config)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_layer.py\", line 205, in __init__\n    ragged=ragged)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 1386, in placeholder\n    x = tf.compat.v1.placeholder(dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 3301, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6894, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3784, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  # Running single-node TF instances on each executor\n",
        "  TFParallel.run(sc, inference, args, args.cluster_size)\n",
        "\n",
        "  #cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, args.num_ps, args.tensorboard, TFCluster.InputMode.TENSORFLOW)\n",
        "  #cluster.shutdown()"
      ],
      "metadata": {
        "id": "P4FFIUru4edB"
      },
      "id": "P4FFIUru4edB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Copy of Downloads.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}